{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/saraltayal/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nUsing TensorFlow backend.\n"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import codecs\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Lambda, Dropout, Bidirectional\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = './train.csv'\n",
    "glove = './glove.6B.100d'\n",
    "# MODEL_SAVING_DIR = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id  qid1  qid2                                          question1  \\\n0   0     1     2  What is the step by step guide to invest in sh...   \n1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2   2     5     6  How can I increase the speed of my internet co...   \n3   3     7     8  Why am I mentally very lonely? How can I solve...   \n4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2  is_duplicate  \n0  What is the step by step guide to invest in sh...             0  \n1  What would happen if the Indian government sto...             0  \n2  How can Internet speed be increased by hacking...             0  \n3  Find the remainder when [math]23^{24}[/math] i...             0  \n4            Which fish would survive in salt water?             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "train_df.dropna()\n",
    "np.shape(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(glove_file):\n",
    "\n",
    "    f = codecs.open(glove_file + \".txt\", 'r', encoding='utf-8')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        split_line = line.split()\n",
    "        word = split_line[0]\n",
    "        embedding = np.array([float(val) for val in split_line[1:]])\n",
    "        model[word] = embedding\n",
    "    return model\n",
    "def get_w2v(sentence, model):\n",
    "    return np.array([model.get(val, np.zeros(100)) for val in sentence.split()], dtype=np.float64)\n",
    "\n",
    "#build the model-> a bit slow ~30seconds \n",
    "model = load_glove_model(glove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input):\n",
    "    if type(input) != type(\"string\"):\n",
    "        print(input)\n",
    "        return \"skip\" \n",
    "    input = input.lower()\n",
    "    input = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", input)\n",
    "    input = re.sub(r\"what's\", \"what is \", input)\n",
    "    input = re.sub(r\"\\'s\", \" \", input)\n",
    "    input = re.sub(r\"\\'ve\", \" have \", input)\n",
    "    input = re.sub(r\"can't\", \"cannot \", input)\n",
    "    input = re.sub(r\"n't\", \" not \", input)\n",
    "    input = re.sub(r\"i'm\", \"i am \", input)\n",
    "    input = re.sub(r\"\\'re\", \" are \", input)\n",
    "    input = re.sub(r\"\\'d\", \" would \", input)\n",
    "    input = re.sub(r\"\\'ll\", \" will \", input)\n",
    "    input = re.sub(r\",\", \" \", input)\n",
    "    input = re.sub(r\"\\.\", \" \", input)\n",
    "    input = re.sub(r\"!\", \" ! \", input)\n",
    "    input = re.sub(r\"\\/\", \" \", input)\n",
    "    input = re.sub(r\"\\^\", \" ^ \", input)\n",
    "    input = re.sub(r\"\\+\", \" + \", input)\n",
    "    input = re.sub(r\"\\-\", \" - \", input)\n",
    "    input = re.sub(r\"\\=\", \" = \", input)\n",
    "    input = re.sub(r\"'\", \" \", input)\n",
    "    input = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", input)\n",
    "    input = re.sub(r\":\", \" : \", input)\n",
    "    input = re.sub(r\" e g \", \" eg \", input)\n",
    "    input = re.sub(r\" b g \", \" bg \", input)\n",
    "    input = re.sub(r\" u s \", \" american \", input)\n",
    "    input = re.sub(r\"\\0s\", \"0\", input)\n",
    "    input = re.sub(r\" 9 11 \", \"911\", input)\n",
    "    input = re.sub(r\"e - mail\", \"email\", input)\n",
    "    input = re.sub(r\"j k\", \"jk\", input)\n",
    "    input = re.sub(r\"\\s{2,}\", \" \", input)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 40000/40000 [00:04<00:00, 9933.14it/s]\n100%|██████████| 40000/40000 [00:04<00:00, 9923.16it/s]\n[]\n404290\n404290\n"
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "indexesToRemove = []\n",
    "\n",
    "lenTrain = np.shape(train_df['question1'])[0]\n",
    "\n",
    "for col in ['question1', 'question2']:\n",
    "    for row in tqdm(range(40000)): #lenTrain\n",
    "        processedText = preprocess(train_df[col][row])\n",
    "        if processedText == \"skip\":\n",
    "            indexesToRemove.append(row)\n",
    "        train_df.at[row,col] = get_w2v(processedText, model)\n",
    "\n",
    "print(indexesToRemove)\n",
    "print(np.shape(train_df['question1'])[0])\n",
    "train_df = train_df.drop(indexesToRemove)\n",
    "print(np.shape(train_df['question1'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "39506\n"
    }
   ],
   "source": [
    "left = train_df['question1'][0:40000].values\n",
    "right = train_df['question2'][0:40000].values\n",
    "Y = train_df['is_duplicate'][0:40000].values\n",
    "\n",
    "maxlen = 35\n",
    "indextracker = []\n",
    "\n",
    "for index in range(len(right)):\n",
    "    if len(left[index]) > maxlen or len(right[index]) > maxlen or len(left[index]) < 3 or len(right[index]) < 3:\n",
    "        indextracker.append(index)\n",
    "left = np.delete(left, indextracker)\n",
    "right = np.delete(right, indextracker)\n",
    "Y = np.delete(Y, indextracker)\n",
    "assert len(left) == len(right) and len(left) == len(Y)\n",
    "print(len(right))\n",
    "\n",
    "#probably need to delete variables etc for memory lol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padZeros(input, maxLen):\n",
    "    if np.shape(input)[0] == maxLen:\n",
    "        return input\n",
    "    lenToPad = maxLen - np.shape(input)[0]\n",
    "    output = np.concatenate((input, np.zeros((lenToPad, 100))))\n",
    "    return output\n",
    "    return np.transpose(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "left = [padZeros(elem, maxlen) for elem in left]\n",
    "right = [padZeros(elem, maxlen) for elem in right]\n",
    "\n",
    "left = np.reshape(left, (np.shape(left)[0], maxlen, 100)) #100 comes from the encoding\n",
    "right = np.reshape(right, (np.shape(right)[0], maxlen, 100)) #100 comes from the encoding\n",
    "Y = np.reshape(Y, (np.shape(Y)[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(39506, 1)\n(39506, 35, 100)\n(39506, 35, 100)\n"
    }
   ],
   "source": [
    "print(np.shape(Y))\n",
    "print(np.shape(left))\n",
    "print(np.shape(right))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[-0.51533   0.83186   0.22457  ... -1.2024    1.1304    0.3479  ]\n [-0.084215  0.69597   0.28383  ... -0.54      0.58031   0.46698 ]\n [-0.23676   0.15659   0.30243  ... -0.16095   0.75331   0.29294 ]\n ...\n [ 0.        0.        0.       ...  0.        0.        0.      ]\n [ 0.        0.        0.       ...  0.        0.        0.      ]\n [ 0.        0.        0.       ...  0.        0.        0.      ]]\n[[ 0.30449  -0.19628   0.20225  ... -0.18385  -0.12432   0.27468 ]\n [ 0.77415  -0.18802  -0.14085  ... -0.15508  -0.84373   0.28243 ]\n [-0.11819   0.012215 -0.065054 ... -0.044096  0.40568  -0.52475 ]\n ...\n [ 0.        0.        0.       ...  0.        0.        0.      ]\n [ 0.        0.        0.       ...  0.        0.        0.      ]\n [ 0.        0.        0.       ...  0.        0.        0.      ]]\n[1]\n(39506, 1)\n"
    }
   ],
   "source": [
    "idx = np.random.randint(len(right))\n",
    "print(left[idx])\n",
    "print(right[idx])\n",
    "print(Y[idx])\n",
    "print(np.shape(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 31604 samples, validate on 7902 samples\nEpoch 1/8\n31604/31604 [==============================] - 49s 2ms/step - loss: 0.2128 - accuracy: 0.6564 - val_loss: 0.2171 - val_accuracy: 0.6592\nEpoch 2/8\n31604/31604 [==============================] - 48s 2ms/step - loss: 0.1910 - accuracy: 0.7042 - val_loss: 0.1905 - val_accuracy: 0.7168\nEpoch 3/8\n31604/31604 [==============================] - 68s 2ms/step - loss: 0.1800 - accuracy: 0.7260 - val_loss: 0.1804 - val_accuracy: 0.7287\nEpoch 4/8\n31604/31604 [==============================] - 46s 1ms/step - loss: 0.1709 - accuracy: 0.7468 - val_loss: 0.1796 - val_accuracy: 0.7269\nEpoch 5/8\n31604/31604 [==============================] - 47s 1ms/step - loss: 0.1616 - accuracy: 0.7633 - val_loss: 0.1767 - val_accuracy: 0.7351\nEpoch 6/8\n31604/31604 [==============================] - 50s 2ms/step - loss: 0.1529 - accuracy: 0.7815 - val_loss: 0.1702 - val_accuracy: 0.7483\nEpoch 7/8\n31604/31604 [==============================] - 57s 2ms/step - loss: 0.1456 - accuracy: 0.7948 - val_loss: 0.1660 - val_accuracy: 0.7585\nEpoch 8/8\n31604/31604 [==============================] - 63s 2ms/step - loss: 0.1386 - accuracy: 0.8085 - val_loss: 0.1688 - val_accuracy: 0.7522\n"
    }
   ],
   "source": [
    "# Model variables\n",
    "n_hidden = 80\n",
    "gradient_clipping_norm = 1.25\n",
    "batch_size = 64\n",
    "n_epoch = 8\n",
    "\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
    "\n",
    "# The visible layer\n",
    "left_input = Input(shape=np.shape(left[0]), dtype='float32')\n",
    "right_input = Input(shape=np.shape(right[0]), dtype='float32')\n",
    "\n",
    "\n",
    "\n",
    "# Since this is a siamese network, both sides share the same LSTM\n",
    "shared_lstm = Bidirectional(LSTM(n_hidden, return_sequences=True))\n",
    "shared_lstm2 = LSTM(n_hidden)\n",
    "\n",
    "left_output = shared_lstm(left_input)\n",
    "right_output = shared_lstm(right_input)\n",
    "\n",
    "left_output = Dropout(0.1)(left_output)\n",
    "left_output = shared_lstm2(left_output)\n",
    "\n",
    "right_output = Dropout(0.1)(right_output)\n",
    "right_output = shared_lstm2(right_output)\n",
    "\n",
    "# Calculates the distance as defined by the MaLSTM model\n",
    "malstm_distance = Lambda(function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
    "\n",
    "# Pack it all up into a model\n",
    "malstm = Model([left_input, right_input], [malstm_distance])\n",
    "\n",
    "# Adadelta optimizer, with gradient clipping by norm\n",
    "optimizer = Adam(clipnorm=gradient_clipping_norm)\n",
    "\n",
    "malstm.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Start training\n",
    "\n",
    "malstm_trained = malstm.fit([left, right], Y, batch_size=batch_size, nb_epoch=n_epoch, validation_split = 0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputA, inputB, model = model):\n",
    "    processedTextA = preprocess(inputA)\n",
    "    processedTextB = preprocess(inputB)\n",
    "    if processedTextA == \"skip\" or processedTextB == \"skip\":\n",
    "        print(\"Input needs to be strings\")\n",
    "        return\n",
    "    vectorizedA = get_w2v(processedTextA, model)\n",
    "    vectorizedB = get_w2v(processedTextB, model)\n",
    "    paddedA = padZeros(vectorizedA, maxlen)\n",
    "    paddedB = padZeros(vectorizedB, maxlen)\n",
    "\n",
    "    prediction = malstm.predict([[paddedA], [paddedB]])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.29617628]]\n[[0.5939616]]\n[[0.21363927]]\n[[0.37795046]]\n[[0.83696353]]\n[[0.38213742]]\n"
    }
   ],
   "source": [
    "print(predict(\"I like to eat\", \"I love to eat\"))\n",
    "print(predict(\"Sally went down the road\", \"Down the road Sally went\"))\n",
    "print(predict(\"I like to eat\", \"I hate to eat\"))\n",
    "print(predict(\"I enjoy to eat\", \"I love to eat\"))\n",
    "print(predict(\"What can make Physics easy to learn?\", \"How can you make physics easy to learn?\"))\n",
    "print(predict(\"This is the statement the Chief Minister gave in the floor of the assembly, which essentially is a fact.\", \"How can a statement the Chief Minister gave in the floor of the assembly, which essentially is a fact, be characterized as a claim?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tricks to try- attention layer\n",
    "#Triplet loss"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bit48ab55c67191446ab6f17aa00e0ca628",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}